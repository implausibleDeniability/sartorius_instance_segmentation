{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/workspaces/sartorius_instance_segmentation')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import skimage.io as io\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchvision.models.detection import maskrcnn_resnet50_fpn\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from skimage.color import gray2rgb\n",
    "from torchvision.ops import nms\n",
    "from pytorch_toolbelt.utils import to_numpy, rle_encode\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from src.visualization import tensor_to_image\n",
    "from src.postprocessing import remove_overlapping_pixels\n",
    "\n",
    "current_dir = Path(\".\")\n",
    "load_dotenv()\n",
    "current_dir.absolute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Global config of configuration\n",
    "test_images_dir = Path(os.environ['dataset_path']) / \"test\"\n",
    "weights_dir = current_dir / \"weights\" / \"maxim_baseline.ckpt\"\n",
    "device = \"cpu\"\n",
    "\n",
    "# Local tunable parameters of evaluation\n",
    "score_threshold = 0.0  # All predictions would be counted, even with low score\n",
    "nms_threshold = 0.1  # Overlapping instances will be dropped, lower - lower overlap is permitted\n",
    "mask_threshold = 0.5  # Cut masks by the threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "assert test_images_dir.is_dir(), f\"Check test dir path for correctness, was looking at {test_images_dir.absolute()}\"\n",
    "assert weights_dir.is_file(), f\"File not found, was looking at {weights_dir.absolute()}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "preprocess_image = A.Compose([\n",
    "    A.Normalize(mean=(0.485,), std=(0.229,)),\n",
    "    ToTensorV2(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = maskrcnn_resnet50_fpn(progress=False, num_classes=2)\n",
    "model.load_state_dict(torch.load(weights_dir, map_location=torch.device(\"cpu\")))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "def predict_masks(image: np.ndarray, model) -> np.ndarray:\n",
    "    \"\"\"Predicts masks for the given single image\"\"\"\n",
    "    device = next(model.parameters()).device\n",
    "    image = preprocess_image(image=image)['image']\n",
    "    image.to(device)\n",
    "    with torch.no_grad():\n",
    "        output = model.forward([image])[0]\n",
    "\n",
    "    scores = output['scores'].detach().cpu()\n",
    "    masks = output['masks'].squeeze().detach().cpu()\n",
    "    boxes = output['boxes'].detach().cpu()\n",
    "\n",
    "    masks = (masks >= mask_threshold).int()\n",
    "\n",
    "    # Now some masks can be empty (all zeros), we need to exclude them\n",
    "    # TODO(shamil): this indexing is ugly\n",
    "    indices = torch.as_tensor([torch.sum(mask) > 0 for mask in masks])\n",
    "    masks, boxes, scores = masks[indices], boxes[indices], scores[indices]\n",
    "\n",
    "    indices = scores >= score_threshold\n",
    "    masks, boxes, scores = masks[indices], boxes[indices], scores[indices]\n",
    "\n",
    "    indices = nms(boxes, scores, nms_threshold)\n",
    "    masks, boxes, scores = masks[indices], boxes[indices], scores[indices]\n",
    "    \n",
    "    answer_masks = remove_overlapping_pixels(masks.numpy())\n",
    "    assert np.max(np.sum(answer_masks, axis=0)) <= 1, \"Masks overlap\"\n",
    "    return answer_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/conda/lib/python3.9/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1634272068185/work/aten/src/ATen/native/TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "answers = {\n",
    "    \"id\": [],\n",
    "    \"predicted\" : [],\n",
    "}\n",
    "for image_path in test_images_dir.glob(\"**/*.png\"):\n",
    "    image = io.imread(str(image_path))\n",
    "    masks = predict_masks(image, model)\n",
    "    answers[\"id\"].extend(image_path.stem for i in range(len(masks)))\n",
    "    answers[\"predicted\"].extend(\" \".join(map(str, rle_encode(mask))) for mask in masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>d48ec7815252</td>\n",
       "      <td>163 14 682 16 1201 18 1720 20 2239 22 2759 22 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>d8bfd1dafdc4</td>\n",
       "      <td>209651 1 210171 1 210690 1 211727 3 212246 4 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>7ae19de7bc2a</td>\n",
       "      <td>57887 11 58406 14 58925 15 59444 16 59964 16 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>d48ec7815252</td>\n",
       "      <td>82231 4 82751 5 83271 6 83791 6 84310 8 84830 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>7ae19de7bc2a</td>\n",
       "      <td>89846 1 90364 5 90884 6 91403 8 91923 8 92443 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>d48ec7815252</td>\n",
       "      <td>87707 1 88226 4 88746 5 89266 6 89786 6 90305 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>d48ec7815252</td>\n",
       "      <td>199049 5 199566 8 200078 2 200085 9 200596 8 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>d8bfd1dafdc4</td>\n",
       "      <td>163975 4 164495 8 165015 9 165534 9 166054 9 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id                                          predicted\n",
       "99   d48ec7815252  163 14 682 16 1201 18 1720 20 2239 22 2759 22 ...\n",
       "185  d8bfd1dafdc4  209651 1 210171 1 210690 1 211727 3 212246 4 2...\n",
       "21   7ae19de7bc2a  57887 11 58406 14 58925 15 59444 16 59964 16 6...\n",
       "116  d48ec7815252  82231 4 82751 5 83271 6 83791 6 84310 8 84830 ...\n",
       "33   7ae19de7bc2a  89846 1 90364 5 90884 6 91403 8 91923 8 92443 ...\n",
       "125  d48ec7815252  87707 1 88226 4 88746 5 89266 6 89786 6 90305 ...\n",
       "109  d48ec7815252  199049 5 199566 8 200078 2 200085 9 200596 8 2...\n",
       "166  d8bfd1dafdc4  163975 4 164495 8 165015 9 165534 9 166054 9 1..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.DataFrame(answers)\n",
    "submission.sample(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
