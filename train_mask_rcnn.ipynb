{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from functools import reduce\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from easydict import EasyDict\n",
    "import torch\n",
    "from torchvision import models\n",
    "import numpy as np\n",
    "from time import time\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from src.dataset import CellDataset\n",
    "from src.postprocessing import postprocess_predictions\n",
    "from src.iou_metric import fast_iou, iou_map\n",
    "logging.basicConfig(filename='train.log', level=logging.INFO, format='%(asctime)s %(message)s')\n",
    "np.random.seed(0)\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/workspaces/sartorius_instance_segmentation')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_dir = Path(\".\") # In my case, it is sartorius_instance_segmentation\n",
    "current_dir.absolute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mimplausible_denyability\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/implausible_denyability/sartorius_instance_segmentation/runs/ri8bvvsj\" target=\"_blank\">first_baseline_with_metric</a></strong> to <a href=\"https://wandb.ai/implausible_denyability/sartorius_instance_segmentation\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/implausible_denyability/sartorius_instance_segmentation/runs/ri8bvvsj?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f9a15d0e3d0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "experiment_name = \"first_baseline_with_metric\"\n",
    "wandb.init(project=\"sartorius_instance_segmentation\", entity=\"implausible_denyability\", name=experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Links to tutorials\n",
    "- Torchvision maskrcnn inputting: [pytorch.org](https://pytorch.org/tutorials/intermediate/torchvision_tutorial.html)\n",
    "- Kaggle baseline notebook: [kaggle.com](https://www.kaggle.com/julian3833/sartorius-starter-torch-mask-r-cnn-lb-0-273)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Global config of dataset, not tunable parameters\n",
    "config = EasyDict(\n",
    "    dataset_path=Path(os.environ[\"dataset_path\"]),\n",
    "    device=\"cuda:1\",\n",
    "    val_size=0.2,\n",
    "    batch_size=6,\n",
    "    num_workers=30,\n",
    "    max_epochs=40,\n",
    "    mask_threshold=0.5,\n",
    "    score_threshold=0.2,\n",
    "    nms_threshold=None,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_transform = A.Compose([\n",
    "    A.Normalize(mean=(0.485,), std=(0.229,)),\n",
    "    # A.ShiftScaleRotate(shift_limit=0.8, border_mode=cv2.BORDER_CONSTANT),\n",
    "    ToTensorV2(),\n",
    "], bbox_params=A.BboxParams(format='pascal_voc', label_fields=['category_ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not change collate function - it was takes from torchvision tutorials\n",
    "train_dataloader = DataLoader(\n",
    "    dataset=CellDataset(cfg=config, mode='train', transform=train_transform),\n",
    "    num_workers=config.num_workers,\n",
    "    batch_size=config.batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=lambda x: tuple(zip(*x))\n",
    ")\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    dataset=CellDataset(cfg=config, mode='val', transform=train_transform),\n",
    "    num_workers=config.num_workers,\n",
    "    batch_size=config.batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=lambda x: tuple(zip(*x))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = config.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def images_to_device(images):\n",
    "    images = list(image.to(device) for image in images)\n",
    "    return images\n",
    "\n",
    "def targets_to_device(targets):\n",
    "    targets = [{key: value.to(device) for key, value in target.items()} for target in targets]\n",
    "    return targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_batch(model, images, targets, optimizer):\n",
    "    optimizer.zero_grad()\n",
    "    images, targets = images_to_device(images), targets_to_device(targets)\n",
    "    output = model(images, targets)\n",
    "    loss = sum(single_loss for single_loss in output.values())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item(), output['loss_mask'].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_batch(model, images, targets):\n",
    "    images = images_to_device(images)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(images)\n",
    "    outputs = postprocess_predictions(\n",
    "        outputs,\n",
    "        mask_threshold=config.mask_threshold,\n",
    "        score_threshold=config.score_threshold,\n",
    "        nms_threshold=config.nms_threshold\n",
    "    )\n",
    "    iou_scores = []\n",
    "    for output, target in zip(outputs, targets):\n",
    "        pred_masks = output['masks']\n",
    "        true_masks = target['masks'].numpy()\n",
    "        score = iou_map(pred_masks, true_masks)\n",
    "        iou_scores.append(score)\n",
    "    return np.mean(iou_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train(model, optimizer, scheduler):\n",
    "    for epoch in range(config.max_epochs):\n",
    "\n",
    "        model.train()\n",
    "        for batch_idx, (images, targets) in tqdm(enumerate(train_dataloader), total=len(train_dataloader)):\n",
    "            loss, mask_loss = train_batch(model, images, targets, optimizer)\n",
    "            wandb.log({\"loss/train\":loss, \"mask_loss/train\":mask_loss, \"lr\": scheduler.get_last_lr()[0]})\n",
    "            scheduler.step()\n",
    "    weights_dir = current_dir / \"weights\"\n",
    "    weights_dir.mkdir(exist_ok=True)\n",
    "    torch.save(model.state_dict(), weights_dir / f\"maskrcnn-{experiment_name}-{datetime.now().__str__()}.ckpt\")\n",
    "    print(f\"saved the weights in weights/maskrcnn-{experiment_name}-{datetime.now().__str__()} folder!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% 0/81 [00:00<?, ?it/s]/conda/lib/python3.9/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1634272068185/work/aten/src/ATen/native/TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      " 79% 64/81 [01:40<00:23,  1.38s/it]"
     ]
    }
   ],
   "source": [
    "model = models.detection.maskrcnn_resnet50_fpn(num_classes=2, progress=False)\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, epochs=config.max_epochs, steps_per_epoch=len(train_dataloader), max_lr=1e-3)\n",
    "train(model=model, optimizer=optimizer, scheduler=scheduler)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
