{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from easydict import EasyDict\n",
    "import torch\n",
    "from torchvision import models\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "from pytorch_toolbelt.utils.rle import rle_decode\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "from scripts.utils import annotation2mask, get_box\n",
    "from scripts.dataset import CellDataset\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Links to tutorials\n",
    "- Torchvision maskrcnn inputting: [pytorch.org](https://pytorch.org/tutorials/intermediate/torchvision_tutorial.html)\n",
    "- Kaggle baseline notebook: [kaggle.com](https://www.kaggle.com/julian3833/sartorius-starter-torch-mask-r-cnn-lb-0-273)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Global config of dataset, not tunable parameters\n",
    "config = EasyDict(\n",
    "    dataset_path=Path(\"/data/kaggle_data/\"),\n",
    "    val_size=0.2,\n",
    "    batch_size=2,\n",
    "    num_workers=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# pascal_voc - inputting bbox coord in format (xmin, ymin, xmax, ymax)\n",
    "valid_transform = A.Compose([\n",
    "    A.Normalize(mean=(0.485,), std=(0.229,)),\n",
    "    A.ShiftScaleRotate(shift_limit=0.8),\n",
    "    ToTensorV2(),\n",
    "], bbox_params=A.BboxParams(format='pascal_voc', label_fields=['category_ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (30, 30)\n",
    "\n",
    "def visualize_dataset(im, boxes, masks):\n",
    "    \"\"\"\n",
    "    Visualization instance of dataset after augmentation\n",
    "    \"\"\"\n",
    "    # torch image preprocessed for plotting with matplotlib\n",
    "    im = np.transpose(im.numpy(), axes=(1, 2, 0))\n",
    "    im = (im - im.min()) / (im.max() - im.min())\n",
    "    im = np.asarray(im * 256., dtype=np.uint8)\n",
    "\n",
    "    image_mask = reduce(lambda x, y: x + y, masks)\n",
    "\n",
    "    image_mask[image_mask > 1] = 1\n",
    "    yellow_mask = np.stack([image_mask, image_mask, np.zeros_like(image_mask)], axis=2)\n",
    "\n",
    "    image_with_mask = np.array(im + 50 * yellow_mask, dtype=np.uint8)\n",
    "\n",
    "    # Drawing red rectangle for each instances\n",
    "    red_color = (255, 0, 0)\n",
    "    for x1, y1, x2, y2 in boxes:\n",
    "        image_with_mask = cv2.rectangle(image_with_mask.copy(), pt1=(int(x1), int(y1)), pt2=(int(x2), int(y2)), color=red_color, thickness=2)\n",
    "    \n",
    "    plt.imshow(image_with_mask)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset = CellDataset(cfg=config, mode='train', transform=valid_transform)\n",
    "\n",
    "image, data = dataset[1]\n",
    "visualize_dataset(image, boxes=data['boxes'], masks=data['masks'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Do not change collate function - it was takes from torchvision tutorials\n",
    "dataloader = DataLoader(dataset=CellDataset(cfg=config, mode='train', transform=valid_transform),\n",
    "                        num_workers=config.num_workers,\n",
    "                        batch_size=config.batch_size,\n",
    "                        collate_fn=lambda x: tuple(zip(*x)))\n",
    "\n",
    "# 2 classes: 0 - background, 1 - cell\n",
    "model = models.detection.maskrcnn_resnet50_fpn(num_classes=2, progress=False)\n",
    "model.train()\n",
    "\n",
    "for image, label in dataloader:\n",
    "    output = model(image, label)\n",
    "    print(f\"output: {output}\")\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
