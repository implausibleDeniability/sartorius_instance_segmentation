{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from functools import reduce\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from easydict import EasyDict\n",
    "import torch\n",
    "from torchvision import models\n",
    "import numpy as np\n",
    "from time import time\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from src.dataset import CellDataset\n",
    "from src.postprocessing import postprocess_predictions\n",
    "from src.iou_metric import iou_map\n",
    "logging.basicConfig(filename='train.log', level=logging.INFO, format='%(asctime)s %(message)s')\n",
    "np.random.seed(0)\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/workspaces/sartorius_instance_segmentation')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_dir = Path(\".\") # In my case, it is sartorius_instance_segmentation\n",
    "current_dir.absolute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Links to tutorials\n",
    "- Torchvision maskrcnn inputting: [pytorch.org](https://pytorch.org/tutorials/intermediate/torchvision_tutorial.html)\n",
    "- Kaggle baseline notebook: [kaggle.com](https://www.kaggle.com/julian3833/sartorius-starter-torch-mask-r-cnn-lb-0-273)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Global config of dataset, not tunable parameters\n",
    "config = EasyDict(\n",
    "    dataset_path=Path(os.environ[\"dataset_path\"]),\n",
    "    device=\"cuda:0\",\n",
    "    val_size=0.2,\n",
    "    batch_size=6,\n",
    "    num_workers=30,\n",
    "    max_epochs=40,\n",
    "    mask_threshold=0.5,\n",
    "    score_threshold=0.2,\n",
    "    nms_threshold=None,\n",
    "\n",
    ")\n",
    "\n",
    "## This is for Shamil's local running\n",
    "# config = EasyDict(\n",
    "#     dataset_path=Path(os.environ[\"dataset_path\"]),\n",
    "#     device=\"cpu\",\n",
    "#     val_size=0.2,\n",
    "#     batch_size=1,\n",
    "#     num_workers=2,\n",
    "#     max_epochs=1,\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# pascal_voc - inputting bbox coord in format (xmin, ymin, xmax, ymax)\n",
    "valid_transform = A.Compose([\n",
    "    A.Normalize(mean=(0.485,), std=(0.229,)),\n",
    "    # A.ShiftScaleRotate(shift_limit=0.8, border_mode=cv2.BORDER_CONSTANT),\n",
    "    ToTensorV2(),\n",
    "], bbox_params=A.BboxParams(format='pascal_voc', label_fields=['category_ids']))\n",
    "\n",
    "test_transform = A.Compose([\n",
    "    A.Normalize(mean=(0.485,), std=(0.229,)),\n",
    "    ToTensorV2(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/sartorius_instance_segmentation/src/dataset.py:59: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1634272068185/work/torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  'masks': torch.as_tensor(masks),\n"
     ]
    }
   ],
   "source": [
    "dataset = CellDataset(cfg=config, mode='train', transform=valid_transform)\n",
    "image, data = dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not change collate function - it was takes from torchvision tutorials\n",
    "train_dataloader = DataLoader(\n",
    "    dataset=CellDataset(cfg=config, mode='train', transform=valid_transform),\n",
    "    num_workers=config.num_workers,\n",
    "    batch_size=config.batch_size,\n",
    "    collate_fn=lambda x: tuple(zip(*x))\n",
    ")\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    dataset=CellDataset(cfg=config, mode='val', transform=valid_transform),\n",
    "    num_workers=config.num_workers,\n",
    "    batch_size=config.batch_size,\n",
    "    collate_fn=lambda x: tuple(zip(*x))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = config.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train(model, optimizer):\n",
    "    for epoch in range(config.max_epochs):\n",
    "        # train\n",
    "        losses = []\n",
    "        mask_losses = []\n",
    "        model.train()\n",
    "        for batch_idx, (images, targets) in tqdm(enumerate(train_dataloader), total=len(train_dataloader)):\n",
    "            break\n",
    "            # output has keys 'loss classifier', 'loss_box_reg', 'loss_mask', 'loss_objectness', 'loss_rpn_box_reg'\n",
    "            # second one is Faster R-CNN bounding box prediction loss\n",
    "            # last one is Region Proposal Network loss, RPN proposes candidate object BBoxes for Faster R-CNN\n",
    "            # 4th - I don't know what is it\n",
    "            optimizer.zero_grad()\n",
    "            images = list(image.to(device) for image in images)\n",
    "            targets = [{key: value.to(device) for key, value in target.items()} for target in targets]\n",
    "\n",
    "            output = model(images, targets)\n",
    "            loss = sum(single_loss for single_loss in output.values())\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            losses.append(loss.item())\n",
    "            mask_losses.append(output['loss_mask'].item())\n",
    "        logging.info(f\"Epoch {epoch}: Mean train epoch loss is {np.mean(losses)}, mask loss is {np.mean(mask_losses)}\")\n",
    "    \n",
    "        # Calculating loss metrics on validation\n",
    "        losses = []\n",
    "        mask_losses = []\n",
    "        model.train()\n",
    "        for batch_idx, (images, targets) in tqdm(enumerate(val_dataloader), total=len(val_dataloader)):\n",
    "            images = list(image.to(device) for image in images)\n",
    "            targets = [{key: value.to(device) for key, value in target.items()} for target in targets]\n",
    "\n",
    "            with torch.no_grad():\n",
    "                output = model(images, targets)\n",
    "\n",
    "            loss = sum(single_loss for single_loss in output.values())\n",
    "\n",
    "            losses.append(loss.item())\n",
    "            mask_losses.append(output['loss_mask'].item())\n",
    "\n",
    "        logging.info(f\"Epoch {epoch}: Mean validation  loss is {np.mean(losses)}, mask loss is {np.mean(mask_losses)}\")\n",
    "        \n",
    "        # Calculating map on validation\n",
    "        model.eval()\n",
    "        iou_scores = []\n",
    "        for batch_idx, (images, targets) in tqdm(enumerate(val_dataloader), total=len(val_dataloader), desc=\"Calculating map of validation\"):\n",
    "            images = list(image.to(device) for image in images)\n",
    "            targets = [{key: value.to(device) for key, value in target.items()} for target in targets]\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = model(images)\n",
    "                \n",
    "            outputs = postprocess_predictions(\n",
    "                outputs,\n",
    "                mask_threshold=config.mask_threshold,\n",
    "                score_threshold=config.score_threshold,\n",
    "                nms_threshold=config.nms_threshold\n",
    "            )\n",
    "\n",
    "            # Iterating through each image in batch\n",
    "            for output, ground_truth in zip(outputs, targets):\n",
    "                pred_masks = output['masks']\n",
    "                true_masks = ground_truth['masks'].cpu().numpy()\n",
    "                score = iou_map(true_masks=true_masks, pred_masks=pred_masks)\n",
    "\n",
    "                iou_scores.append(score)\n",
    "\n",
    "        logging.info(f\"Epoch: {epoch}: map score: {np.mean(iou_scores)}\")\n",
    "\n",
    "\n",
    "    weights_dir = current_dir / \"weights\"\n",
    "    weights_dir.mkdir(exist_ok=True)\n",
    "    torch.save(model.state_dict(), weights_dir / f\"maskrcnn-{datetime.now().__str__()}.ckpt\")\n",
    "    print(f\"saved the weights in weights/maskrcnn-{datetime.now().__str__()} folder!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 2 classes: 0 - background, 1 - cell\n",
    "model = models.detection.maskrcnn_resnet50_fpn(num_classes=2, progress=False)\n",
    "model.to(device)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating map of validation:   0% 0/21 [00:00<?, ?it/s]/conda/lib/python3.9/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1634272068185/work/aten/src/ATen/native/TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before processing fn 14:52:46.610868\n",
      "after processing fn 14:52:54.862666\n",
      "map score=0.0\n",
      "map score=0.0\n",
      "map score=0.0\n",
      "map score=0.0\n",
      "map score=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating map of validation:   5% 1/21 [05:31<1:50:21, 331.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "map score=0.0\n",
      "before processing fn 14:57:52.593895\n",
      "after processing fn 14:57:59.703786\n",
      "map score=0.0\n",
      "map score=0.0\n",
      "map score=0.0\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "train(model=model, optimizer=optimizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
